{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8f0859",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdetection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m maskrcnn_resnet50_fpn\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# Try importing kagglehub for auto-download\n",
    "try:\n",
    "    import kagglehub\n",
    "except ImportError:\n",
    "    kagglehub = None\n",
    "    print(\"Warning: 'kagglehub' not installed. Auto-download might fail.\")\n",
    "    print(\"Run: pip install kagglehub\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# HELPER: DEBUG FILE STRUCTURE\n",
    "# ---------------------------------------------------------\n",
    "def print_directory_structure(startpath):\n",
    "    print(f\"\\n--- Debugging Structure for: {startpath} ---\")\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        # Print first 3 files only to keep log short\n",
    "        for f in files[:3]:\n",
    "            print(f\"{subindent}{f}\")\n",
    "        if len(files) > 3:\n",
    "            print(f\"{subindent}... ({len(files)-3} more files)\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. DATASET SETUP & DOWNLOADER\n",
    "# ---------------------------------------------------------\n",
    "def download_and_prep_datasets():\n",
    "    \"\"\"\n",
    "    Downloads SeaClear and TrashCan datasets using kagglehub.\n",
    "    Ensures they are saved LOCALLY in the script's directory.\n",
    "    \"\"\"\n",
    "    print(\"\\n[1/4] Checking Datasets...\")\n",
    "    \n",
    "    # --- A. SeaClear Download ---\n",
    "    local_seaclear_path = \"./seaclear_data\"\n",
    "    if not os.path.exists(local_seaclear_path) or not os.listdir(local_seaclear_path):\n",
    "        print(\"   -> Fetching SeaClear (via kagglehub)...\")\n",
    "        try:\n",
    "            cache_path = kagglehub.dataset_download(\"jocelyndumlao/seaclear-marine-debris-detection-and-segmentation\")\n",
    "            print(f\"      Cached at: {cache_path}\")\n",
    "            print(f\"      Moving to local dir: {local_seaclear_path}...\")\n",
    "            if os.path.exists(local_seaclear_path):\n",
    "                shutil.rmtree(local_seaclear_path)\n",
    "            shutil.copytree(cache_path, local_seaclear_path, dirs_exist_ok=True)\n",
    "        except Exception as e:\n",
    "            print(f\"      Error downloading SeaClear: {e}\")\n",
    "            os.makedirs(local_seaclear_path, exist_ok=True)\n",
    "    else:\n",
    "        print(f\"   -> SeaClear already exists at {local_seaclear_path}\")\n",
    "\n",
    "    # --- B. TrashCan Download ---\n",
    "    local_trashcan_path = \"./trashcan_data\"\n",
    "    if not os.path.exists(local_trashcan_path) or not os.listdir(local_trashcan_path):\n",
    "        print(\"   -> Fetching TrashCan (via kagglehub)...\")\n",
    "        try:\n",
    "            cache_path = kagglehub.dataset_download(\"yasht123/trashcan\")\n",
    "            print(f\"      Cached at: {cache_path}\")\n",
    "            print(f\"      Moving to local dir: {local_trashcan_path}...\")\n",
    "            if os.path.exists(local_trashcan_path):\n",
    "                shutil.rmtree(local_trashcan_path)\n",
    "            shutil.copytree(cache_path, local_trashcan_path, dirs_exist_ok=True)\n",
    "            print(f\"      TrashCan ready at: {local_trashcan_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"      Error downloading TrashCan: {e}\")\n",
    "            print(\"      If this persists, please download manually.\")\n",
    "            os.makedirs(local_trashcan_path, exist_ok=True)\n",
    "    else:\n",
    "        print(f\"   -> TrashCan already exists at {local_trashcan_path}\")\n",
    "\n",
    "    return local_seaclear_path, local_trashcan_path\n",
    "\n",
    "def find_dataset_components(root_dir, dataset_name):\n",
    "    \"\"\"\n",
    "    Recursively searches for the 'images' folder and a valid 'json' annotation file.\n",
    "    \"\"\"\n",
    "    img_dir = None\n",
    "    ann_file = None\n",
    "    \n",
    "    print(f\"   Searching {dataset_name} in: {root_dir}\")\n",
    "\n",
    "    # 1. Find ALL JSON files\n",
    "    json_candidates = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                json_candidates.append(os.path.join(root, file))\n",
    "    \n",
    "    # 2. Heuristic for Annotation File\n",
    "    for f in json_candidates:\n",
    "        if \"train\" in f.lower() and \"instance\" in f.lower():\n",
    "            ann_file = f\n",
    "            break\n",
    "    if not ann_file and json_candidates:\n",
    "        for f in json_candidates:\n",
    "            if \"train\" in f.lower():\n",
    "                ann_file = f\n",
    "                break\n",
    "    if not ann_file and json_candidates:\n",
    "        ann_file = json_candidates[0] \n",
    "\n",
    "    # 3. Find Image Directory\n",
    "    candidate_img_dirs = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        image_count = sum(1 for f in files if f.lower().endswith(('.jpg', '.png', '.jpeg')))\n",
    "        if image_count > 5: \n",
    "            candidate_img_dirs.append((root, image_count))\n",
    "    \n",
    "    candidate_img_dirs.sort(key=lambda x: x[1], reverse=True)\n",
    "    if candidate_img_dirs:\n",
    "        img_dir = candidate_img_dirs[0][0]\n",
    "\n",
    "    if img_dir and ann_file:\n",
    "        print(f\"      [OK] Found images in: .../{os.path.basename(img_dir)} ({candidate_img_dirs[0][1]} images)\")\n",
    "        print(f\"      [OK] Found annotation: .../{os.path.basename(ann_file)}\")\n",
    "    else:\n",
    "        print(f\"      [FAIL] Could not locate components.\")\n",
    "        print_directory_structure(root_dir)\n",
    "\n",
    "    return img_dir, ann_file\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. COLOR SPACE TRANSFORMATIONS\n",
    "# ---------------------------------------------------------\n",
    "class ColorSpaceTransform:\n",
    "    def __init__(self, color_space='RGB'):\n",
    "        self.color_space = color_space.upper()\n",
    "\n",
    "    def __call__(self, image_rgb):\n",
    "        if self.color_space == 'HSV':\n",
    "            img = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)\n",
    "        elif self.color_space == 'LAB':\n",
    "            img = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2LAB)\n",
    "        elif self.color_space == 'HSL':\n",
    "            img = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HLS)\n",
    "        elif self.color_space == 'GRAY':\n",
    "            img = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "            img = cv2.merge([img, img, img]) \n",
    "        else:\n",
    "            img = image_rgb \n",
    "\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img_tensor = torch.from_numpy(img).permute(2, 0, 1)\n",
    "        return img_tensor\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. DATASET LOADER (COCO Format)\n",
    "# ---------------------------------------------------------\n",
    "class MarineDebrisDataset(Dataset):\n",
    "    def __init__(self, img_dir, annotation_file, color_space='RGB'):\n",
    "        self.img_dir = img_dir\n",
    "        self.color_transformer = ColorSpaceTransform(color_space)\n",
    "        self.valid_dataset = False\n",
    "        \n",
    "        if img_dir and annotation_file and os.path.exists(annotation_file):\n",
    "            try:\n",
    "                print(f\"   Loading JSON: {os.path.basename(annotation_file)}...\")\n",
    "                with open(annotation_file, 'r') as f:\n",
    "                    self.coco_data = json.load(f)\n",
    "                self.valid_dataset = True\n",
    "            except Exception as e:\n",
    "                print(f\"   Error parsing JSON: {e}\")\n",
    "                self.valid_dataset = False\n",
    "        \n",
    "        if self.valid_dataset:\n",
    "            self.images = {}\n",
    "            self.ids = []\n",
    "            self.ann_map = {}\n",
    "            \n",
    "            for ann in self.coco_data.get('annotations', []):\n",
    "                img_id = ann['image_id']\n",
    "                if img_id not in self.ann_map: self.ann_map[img_id] = []\n",
    "                self.ann_map[img_id].append(ann)\n",
    "\n",
    "            print(f\"   Mapping images from {os.path.basename(self.img_dir)}...\")\n",
    "            count_found = 0\n",
    "            for img in self.coco_data['images']:\n",
    "                path_opts = [\n",
    "                    os.path.join(self.img_dir, img['file_name']),\n",
    "                    os.path.join(self.img_dir, os.path.basename(img['file_name']))\n",
    "                ]\n",
    "                final_path = None\n",
    "                for p in path_opts:\n",
    "                    if os.path.exists(p):\n",
    "                        final_path = p\n",
    "                        break\n",
    "                \n",
    "                if final_path:\n",
    "                    self.images[img['id']] = {'path': final_path, 'info': img}\n",
    "                    self.ids.append(img['id'])\n",
    "                    count_found += 1\n",
    "            \n",
    "            print(f\"   {count_found} valid images matched.\")\n",
    "            if count_found == 0:\n",
    "                print(\"   WARNING: JSON loaded but no images matched filenames.\")\n",
    "                self.valid_dataset = False\n",
    "        \n",
    "        if not self.valid_dataset:\n",
    "            print(\"   Using Mock Data (Dataset load failed)\")\n",
    "            self.ids = [1, 2] \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.valid_dataset:\n",
    "            img_id = self.ids[index]\n",
    "            data = self.images[img_id]\n",
    "            path = data['path']\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                img = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "            else:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            anns = self.ann_map.get(img_id, [])\n",
    "        else:\n",
    "            img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "            anns = []\n",
    "\n",
    "        img_tensor = self.color_transformer(img)\n",
    "        \n",
    "        boxes, labels, masks_list = [], [], []\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        if self.valid_dataset and anns:\n",
    "            for ann in anns:\n",
    "                if 'bbox' not in ann: continue\n",
    "                x, y, bw, bh = ann['bbox']\n",
    "                if bw > 1 and bh > 1: \n",
    "                    boxes.append([x, y, x + bw, y + bh])\n",
    "                    labels.append(1)\n",
    "                    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "                    if 'segmentation' in ann:\n",
    "                        seg = ann['segmentation']\n",
    "                        if isinstance(seg, list) and len(seg) > 0 and isinstance(seg[0], list):\n",
    "                             for s in seg:\n",
    "                                poly = np.array(s).reshape((-1, 2)).astype(np.int32)\n",
    "                                cv2.fillPoly(mask, [poly], 1)\n",
    "                    masks_list.append(mask)\n",
    "        elif not self.valid_dataset:\n",
    "            boxes.append([100, 100, 200, 200])\n",
    "            labels.append(1)\n",
    "            mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            mask[100:200, 100:200] = 1\n",
    "            masks_list.append(mask)\n",
    "\n",
    "        if len(boxes) > 0:\n",
    "            boxes_t = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            labels_t = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            masks_t = torch.as_tensor(np.array(masks_list), dtype=torch.uint8)\n",
    "        else:\n",
    "            boxes_t = torch.zeros((0, 4), dtype=torch.float32)\n",
    "            labels_t = torch.zeros((0,), dtype=torch.int64)\n",
    "            masks_t = torch.zeros((0, h, w), dtype=torch.uint8)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes_t, \"labels\": labels_t, \"masks\": masks_t,\n",
    "            \"image_id\": torch.tensor([index])\n",
    "        }\n",
    "        return img_tensor, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. MODEL & EVALUATION LOGIC\n",
    "# ---------------------------------------------------------\n",
    "def get_model(num_classes):\n",
    "    \"\"\"\n",
    "    Configures Mask R-CNN with specific settings for Underwater Waste.\n",
    "    \"\"\"\n",
    "    # 1. Load Pretrained\n",
    "    model = maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "    \n",
    "    # 2. Replace Box Predictor (Classes: Background + Waste)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    # 3. Replace Mask Predictor\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)\n",
    "    \n",
    "    # 4. HANDLE CLASS IMBALANCE & SMALL OBJECTS\n",
    "    # Increase positive fraction: forces model to sample more foreground (trash) \n",
    "    # regions during loss calculation. Default is 0.25.\n",
    "    model.roi_heads.fg_bg_sampler.positive_fraction = 0.50\n",
    "    \n",
    "    # Increase detections per image to catch dense trash clusters\n",
    "    model.roi_heads.detections_per_img = 100\n",
    "    \n",
    "    return model\n",
    "\n",
    "def calculate_iou(pred, gt):\n",
    "    inter = np.logical_and(pred, gt).sum()\n",
    "    union = np.logical_or(pred, gt).sum()\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "def train_and_evaluate(dataset_name, color_space, img_dir, ann_file, device, epochs=50):\n",
    "    print(f\"\\n--- Running: {dataset_name} | {color_space} ---\")\n",
    "    \n",
    "    # 1. Prepare Data (FULL DATASET USE)\n",
    "    dataset = MarineDebrisDataset(img_dir, ann_file, color_space)\n",
    "    if len(dataset) < 5:\n",
    "        print(\"Dataset too small. Skipping.\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    # Random Split - Using 80/20 split on full data\n",
    "    indices = torch.randperm(len(dataset)).tolist()\n",
    "    split = int(0.8 * len(dataset))\n",
    "    \n",
    "    train_ds = torch.utils.data.Subset(dataset, indices[:split]) \n",
    "    test_ds = torch.utils.data.Subset(dataset, indices[split:])\n",
    "\n",
    "    print(f\"   Training on {len(train_ds)} images | Validation on {len(test_ds)} images\")\n",
    "    print(f\"   Epochs: {epochs}\")\n",
    "\n",
    "    # Increase batch size if GPU allows to stabilize gradients\n",
    "    batch_size = 4 \n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "    # 2. Model & Optimizer\n",
    "    model = get_model(2).to(device)\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "    \n",
    "    # Learning Rate Scheduler (Essential for 50+ epochs)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "    # 3. Train Loop\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for imgs, tgts in train_loader:\n",
    "            imgs = list(img.to(device) for img in imgs)\n",
    "            tgts = [{k: v.to(device) for k, v in t.items()} for t in tgts]\n",
    "            \n",
    "            if not imgs: continue\n",
    "            \n",
    "            loss_dict = model(imgs, tgts)\n",
    "            loss = sum(l for l in loss_dict.values())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        if (ep+1) % 5 == 0:\n",
    "            avg_loss = np.mean(losses) if losses else 0\n",
    "            print(f\"   Epoch {ep+1}/{epochs} | Loss: {avg_loss:.4f} | LR: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "    # 4. Evaluation Loop\n",
    "    model.eval()\n",
    "    ious = []\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, tgts in test_loader:\n",
    "            imgs = list(img.to(device) for img in imgs)\n",
    "            output = model(imgs)[0]\n",
    "            target = tgts[0]\n",
    "            \n",
    "            gt_masks = target['masks'].cpu().numpy()\n",
    "            if len(gt_masks) == 0: continue\n",
    "\n",
    "            if len(output['masks']) > 0:\n",
    "                pred_masks = (output['masks'][:, 0].cpu().numpy() > 0.5).astype(np.uint8)\n",
    "                \n",
    "                matched = set()\n",
    "                for p_mask in pred_masks:\n",
    "                    best_iou = 0\n",
    "                    best_idx = -1\n",
    "                    for idx, g_mask in enumerate(gt_masks):\n",
    "                        iou = calculate_iou(p_mask, g_mask)\n",
    "                        if iou > best_iou:\n",
    "                            best_iou = iou\n",
    "                            best_idx = idx\n",
    "                    \n",
    "                    if best_iou > 0.5:\n",
    "                        if best_idx not in matched:\n",
    "                            tp += 1\n",
    "                            matched.add(best_idx)\n",
    "                            ious.append(best_iou)\n",
    "                        else:\n",
    "                            fp += 1\n",
    "                    else:\n",
    "                        fp += 1\n",
    "                fn += len(gt_masks) - len(matched)\n",
    "            else:\n",
    "                fn += len(gt_masks)\n",
    "\n",
    "    mean_iou = np.mean(ious) if ious else 0\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "    \n",
    "    print(f\"   Result -> F1: {f1:.4f} | mIoU: {mean_iou:.4f}\")\n",
    "    return f1, mean_iou\n",
    "\n",
    "def plot_results(results):\n",
    "    print(\"\\n[4/4] Plotting Results...\")\n",
    "    datasets = list(results.keys())\n",
    "    if not datasets:\n",
    "        print(\"No datasets to plot.\")\n",
    "        return\n",
    "\n",
    "    color_spaces = list(results[datasets[0]].keys())\n",
    "    x = np.arange(len(datasets))\n",
    "    width = 0.2\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    for i, color in enumerate(color_spaces):\n",
    "        scores = [results[ds].get(color, {'f1':0})['f1'] for ds in datasets]\n",
    "        offset = width * i\n",
    "        rects = ax.bar(x + offset, scores, width, label=color)\n",
    "\n",
    "    ax.set_ylabel('F1 Score')\n",
    "    ax.set_title('Impact of Color Space (50 Epochs, Full Data)')\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(datasets)\n",
    "    ax.legend(title=\"Color Space\")\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('experiment_results_full.png')\n",
    "    print(\"Graph saved to 'experiment_results_full.png'\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. MAIN EXECUTION\n",
    "# ---------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # --- CROSS-PLATFORM DIAGNOSTICS ---\n",
    "    print(\"\\n--- System Diagnostics ---\")\n",
    "    print(f\"   OS: {sys.platform}\")\n",
    "    print(f\"   Python: {sys.version.split()[0]}\")\n",
    "    print(f\"   PyTorch: {torch.__version__}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   GPU Available: YES - {torch.cuda.get_device_name(0)}\")\n",
    "        DEVICE = torch.device('cuda')\n",
    "    else:\n",
    "        print(\"   GPU Available: NO\")\n",
    "        print(\"   [WARNING] Running on CPU. Training will be slow.\")\n",
    "        \n",
    "        # Advice based on Platform\n",
    "        if sys.platform == 'linux':\n",
    "            print(\"   To fix on Linux/WSL:\")\n",
    "            print(\"   1. Stop this script.\")\n",
    "            print(\"   2. Run: pip install torch torchvision --upgrade\")\n",
    "            print(\"      (PyTorch on Linux usually finds CUDA automatically)\")\n",
    "        elif sys.platform == 'win32':\n",
    "             print(\"   To fix on Windows:\")\n",
    "             print(\"   1. Stop this script.\")\n",
    "             print(\"   2. Run: pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu121\")\n",
    "        \n",
    "        DEVICE = torch.device('cpu')\n",
    "    print(\"--------------------------\\n\")\n",
    "\n",
    "    # UPDATED CONFIGURATION\n",
    "    EPOCHS_PER_RUN = 50 \n",
    "    \n",
    "    # 1. Download\n",
    "    p_seaclear, p_trashcan = download_and_prep_datasets()\n",
    "    \n",
    "    # 2. Locate components\n",
    "    ds_paths = {\n",
    "        'SeaClear': find_dataset_components(p_seaclear, 'SeaClear'),\n",
    "        'TrashCan': find_dataset_components(p_trashcan, 'TrashCan')\n",
    "    }\n",
    "    \n",
    "    # 3. Experiment Loop\n",
    "    color_spaces_to_test = ['RGB', 'HSV', 'LAB']\n",
    "    results_data = {}\n",
    "\n",
    "    print(f\"\\n[2/4] Starting Full Experiments (Epochs={EPOCHS_PER_RUN}) on Device: {DEVICE}\")\n",
    "    \n",
    "    for ds_name, (img_dir, ann_file) in ds_paths.items():\n",
    "        if not img_dir or not ann_file:\n",
    "            print(f\"Skipping {ds_name} (Missing files)\")\n",
    "            continue\n",
    "            \n",
    "        results_data[ds_name] = {}\n",
    "        \n",
    "        for cs in color_spaces_to_test:\n",
    "            f1, iou = train_and_evaluate(ds_name, cs, img_dir, ann_file, DEVICE, EPOCHS_PER_RUN)\n",
    "            results_data[ds_name][cs] = {'f1': f1, 'iou': iou}\n",
    "\n",
    "    # 4. Save & Plot\n",
    "    print(\"\\n[3/4] Experiment Complete. Saving Summary...\")\n",
    "    with open(\"results_summary_full.txt\", \"w\") as f:\n",
    "        f.write(json.dumps(results_data, indent=4))\n",
    "        \n",
    "    if results_data:\n",
    "        plot_results(results_data)\n",
    "    else:\n",
    "        print(\"No results to plot.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
